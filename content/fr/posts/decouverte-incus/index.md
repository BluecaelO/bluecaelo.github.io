---
title: DÃ©couverte de Incus
date: 2025-08-27
description: Cette article a pour but d'explorer et de tester Incus.
tags:
  - Incus
  - lxc
  - ovn
---

![Image](img/Billboard.svg)

## Introduction

Ce lab n'a pas de but particulier. J'ai simplement entendu parler d'une technologie plutÃ´t sympa et j'ai voulu l'essayer.
Cette technologie, c'est **Incus**. Ã€ l'instar de Docker, Incus sert Ã  gÃ©rer des conteneurs. Cependant, il dispose de fonctionnalitÃ©s plus Ã©tendues, comme :

  - un contrÃ´le rÃ©seau plus complet,
  - la possibilitÃ© de faire tourner des conteneurs LXC, OCI ainsi que des machines virtuelles (VM),
  - la gestion des utilisateurs,
  - etc.

Pour plus de dÃ©tails, je vous invite Ã  consulter la [documentation officielle](https://linuxcontainers.org/incus/docs/main/).

## PrÃ©requis

Une machine virtuelle avec au moins 2 Go de RAM.

## Topologie

![Image](img/topo.svg)

Pour expÃ©rimenter Incus, j'ai mis en place une topologie composÃ©e de :

  - un serveur web,
  - un serveur de collecte de mÃ©triques,
  - un serveur de supervision.

> Ici, je ne vais pas m'attarder sur la configuration de Prometheus, Grafana ou Nginx, mais principalement sur celle d'Incus.


### Les types de rÃ©seaux

Incus supporte plusieurs types de rÃ©seaux. Celui qui nous intÃ©resse ici est le rÃ©seau de type **OVN**.
Contrairement Ã  un rÃ©seau bridge, un rÃ©seau OVN permet :

  - de dÃ©finir des ACL (listes de contrÃ´le d'accÃ¨s) entre les instances d'un mÃªme sous-rÃ©seau (plus prÃ©cisÃ©ment, Ã  la mÃªme interface rÃ©seau),
  - d'avoir une topologie plus contrÃ´lÃ©e (notamment en cluster).

> Pour la culture ðŸ§  : OVN est un systÃ¨me de **SDN (Software-Defined Networking)** qui permet d'avoir une abstraction du rÃ©seau virtuel. Il est trÃ¨s pratique si vous souhaitez avoir un certain contrÃ´le sur le rÃ©seau, en particulier dans un cluster.

-----

## Configuration

### Installation de Incus

L'installation dÃ©pend de votre OS ou gestionnaire de paquets. Suivez la documentation officielle : [Installation d'Incus](https://linuxcontainers.org/incus/docs/main/installing/#installing)

#### Configuration de base

```bash
# CrÃ©er un groupe d'administration pour Incus
sudo adduser \$USER incus-admin
sudo newgrp incus-admin
# Initialiser Incus avec la configuration minimale
incus admin init --minimal
```

### Configuration de l'accÃ¨s Ã  distance

#### Exposer le serveur

```bash
incus config set core.https_address :8443
```

> La commande ci-dessus expose entiÃ¨rement lâ€™API dâ€™Incus, ce qui signifie quâ€™elle est accessible depuis toutes les interfaces rÃ©seau.
> Je vous recommande donc de spÃ©cifier lâ€™adresse IP dâ€™Ã©coute que vous souhaitez utiliser pour le management de votre serveur.
> `incus config set core.https_address <listen address>:8443`

#### Installer le client Incus

Sur une machine distante :

```bash
sudo dnf install incus-client # Fedora
```

#### CrÃ©er un token de confiance

Sur le serveur Incus :

```bash
incus config trust add <nom_du_client>
```

Puis sur le client :

```bash
incus remote add <nom_du_client> <adresse_IP_du_serveur>
```

Incus va ensuite vous demander de renseigner le token gÃ©nÃ©rÃ© lors de la commande prÃ©cÃ©dente.

-----

## Mise en place de l'infrastructure

### Installation et configuration de OVN

```bash
sudo ovs-vsctl set open_vswitch . \
   external_ids:ovn-remote=unix:/run/ovn/ovnsb_db.sock \
   external_ids:ovn-encap-type=geneve \
   external_ids:ovn-encap-ip=127.0.0.1
```

Ã€ exÃ©cuter une seule fois, sur l'hÃ´te.

### CrÃ©ation du rÃ©seau bridge parent

Les rÃ©seaux OVN ont un rÃ©seau parent, qui peut Ãªtre soit un rÃ©seau de type bridge, soit un rÃ©seau physique.
Dans mon cas, j'ai personnellement crÃ©Ã© un rÃ©seau bridge dÃ©diÃ©.

```bash
incus network create ovn-bridge
```

Ensuite, on configure le rÃ©seau `ovn-bridge` :

```bash
incus network set ovn-bridge \
Â  Â  ipv4.dhcp.ranges=10.142.205.1-10.142.205.100 \
Â  Â  ipv4.ovn.ranges=10.142.205.101-10.142.205.254 \
Â  Â  ipv4.routes=192.168.10.0/24,192.168.20.0/24
```

  - `ipv4.dhcp.ranges` : correspond Ã  la plage d'adresses rÃ©servÃ©e aux machines directement connectÃ©es au rÃ©seau `ovn-bridge`.
  - `ipv4.ovn.ranges` : correspond Ã  la plage d'adresses rÃ©servÃ©e aux routeurs OVN qui seront connectÃ©s Ã  `ovn-bridge`.
  - `ipv4.routes` : dÃ©finit les sous-rÃ©seaux routÃ©s via les routeurs OVN. Dans notre cas, cela correspond aux rÃ©seaux monitoring (192.168.10.0/24) et web (192.168.20.0/24).

### CrÃ©ation des rÃ©seaux OVN

Maintenant, il suffit de crÃ©er des rÃ©seaux OVN en s'appuyant sur la configuration du rÃ©seau parent. Cela se traduit par les commandes suivantes :

```bash
# CrÃ©ation du rÃ©seau pour les instances de monitoring
incus network create monitoring network=ovn-bridge --type=ovn \
Â  Â  ipv4.address=192.168.10.1/24 ipv4.nat="true" ipv6.address=none
# CrÃ©ation du rÃ©seau pour les instances web
incus network create web network=ovn-bridge --type=ovn \
Â  Â  ipv4.address=192.168.20.1/24 ipv4.nat="true" ipv6.address=none
```

  - `network=ovn-bridge` : indique que le rÃ©seau OVN s'appuie sur le bridge `ovn-bridge` comme rÃ©seau parent.
  - `--type=ovn` : spÃ©cifie qu'il s'agit d'un rÃ©seau de type OVN.
  - `ipv4.address` : dÃ©finit l'adresse IP du routeur OVN et le sous-rÃ©seau utilisÃ©.
  - `ipv4.nat="true"` : active la traduction d'adresses (NAT). Sans le NAT, l'accÃ¨s Ã  Internet n'est pas possible.
  - `ipv6.address=none` : dÃ©sactive IPv6.

### DÃ©ploiement des instances

Pour crÃ©er une instance, nous devons spÃ©cifier :

- le serveur dâ€™images,
- lâ€™image Ã  utiliser,
- le nom de lâ€™instance,
- le rÃ©seau auquel lâ€™instance sera connectÃ©e.

>Ã€ noter quâ€™il existe de nombreux autres paramÃ¨tres que vous pouvez retrouver [ici](https://linuxcontainers.org/incus/docs/main/instances/).


```bash
# Monitoring
incus launch images:debian/12 prometheus --network monitoring
incus launch images:debian/12 grafana --network monitoring
# Web
incus launch images:debian/12 nginx --network web
```

Ci-dessus, je lance des conteneurs basÃ©s sur lâ€™image debian/12, issue du serveur dâ€™images officiel dâ€™Incus. Jâ€™associe ensuite chacun dâ€™eux Ã  son rÃ©seau respectif grÃ¢ce Ã  lâ€™option `--network`.

Par dÃ©faut, les instances reÃ§oivent une adresse IP attribuÃ©e automatiquement par le rÃ©seau auquel elles sont connectÃ©es. Si ces adresses ne vous conviennent pas, il est toujours possible de configurer les interfaces rÃ©seau (NICs) des instances manuellement.

```bash
incus config stop <instance>
incus config device set <instance> eth0 ipv4.address=<ip_address>
# exemple
incus config stop nginx
incus config device set nginx eth0 ipv4.address=192.168.20.2
```

### Exposition des services

Dans l'Ã©tat actuel, nous n'avons pas la possibilitÃ© d'accÃ©der aux services depuis le rÃ©seau local (LAN). Or, nous avons trois services Ã  exposer :

  - Prometheus sur le port 9090
  - Grafana sur le port 3000
  - Nginx sur le port 80

L'objectif est de rendre ces services accessibles depuis le LAN. Pour cela, nous allons ajouter un **device de type proxy** Ã  chaque instance.

```bash
incus config device add <instance> \
Â  Â  <nom_du_device> proxy \
Â  Â  listen=tcp:<adresse_de_l_hÃ´te>:<port_de_l_hÃ´te> \
Â  Â  connect=tcp:<adresse_du_conteneur>:<port_interne>
```

Configuration pour le Lab.

```bash
# Exposition de Prometheus (port 9090)
incus config device add prometheus \
Â  Â  proxy proxy \
Â  Â  listen=tcp:<adresse_de_l_hÃ´te>:9090 \
Â  Â  connect=tcp:192.168.10.2:9090
# Exposition de Grafana (port 3000)
incus config device add grafana \
Â  Â  proxy proxy \
Â  Â  listen=tcp:<adresse_de_l_hÃ´te>:3000 \
Â  Â  connect=tcp:192.168.10.3:3000
# Exposition de Nginx (port 80 vers 8080 sur l'hÃ´te)
incus config device add nginx \
Â  Â  proxy proxy \
Â  Â  listen=tcp:<adresse_de_l_hÃ´te>:8080 \
Â  Â  connect=tcp:192.168.20.2:80
```

### Configuration d'Incus pour le monitoring

#### Exposer le point de terminaison

Afin que Prometheus puisse rÃ©cupÃ©rer les mÃ©triques d'Incus, nous devons, dans un premier temps, exposer le point de terminaison de mÃ©triques. Pour cela, il suffit d'exÃ©cuter la commande suivante :

```bash
incus config set core.metrics_address "<listen_address>:8443"
```

Ici, l'adresse d'Ã©coute correspond Ã  l'adresse IP du rÃ©seau `ovn-bridge`.

> Notez que si vous avez exposÃ© entiÃ¨rement l'API d'Incus (chose Ã  Ã©viter), vous n'avez pas besoin d'entrer la commande ci-dessus.

#### CrÃ©ation des certificats

Comme pour lâ€™accÃ¨s Ã  distance, Incus nÃ©cessite des certificats afin dâ€™exposer en toute sÃ©curitÃ© le point de terminaison des mÃ©triques. Nous avons besoin du fichier `server.crt`, qui correspond au certificat public dâ€™Incus. Il se trouve dans le rÃ©pertoire `/var/lib/incus/`.

Commencez par gÃ©nÃ©rer une paire de clÃ©s et un certificat auto-signÃ© :

```bash
openssl req -x509 -newkey ec -pkeyopt ec_paramgen_curve:secp384r1 \
Â  Â  -sha384 -keyout metrics.key -nodes -out metrics.crt -days 3650 \
Â  Â  -subj "/CN=metrics.local"
```

Ajoutez ensuite le certificat gÃ©nÃ©rÃ© dans la liste des sources de confiance pour les mÃ©triques :

```bash
incus config trust add-certificate metrics.crt --type=metrics
```

CrÃ©ez un dossier pour les certificats dans l'instance Prometheus, puis transfÃ©rez les fichiers nÃ©cessaires :

```bash
incus exec prometheus -- mkdir -p /etc/prometheus/tls
incus file push /var/lib/incus/server.crt prometheus/etc/prometheus/tls
incus file push metrics.key prometheus/etc/prometheus/tls
incus file push metrics.crt prometheus/etc/prometheus/tls
```

Enfin, appliquez les bons droits Ã  ces fichiers depuis l'instance :

```bash
# Ã€ exÃ©cuter dans lâ€™instance Prometheus
chown -R prometheus:prometheus /etc/prometheus/tls
```

### Configuration de Prometheus

Afin d'installer Prometheus, vous devez :

  - le tÃ©lÃ©charger et l'installer Ã  partir des archives officielles,
  - en faire un service systemd (ou autre selon votre systÃ¨me).

Concernant la procÃ©dure d'installation, je vous laisse faire : il existe de nombreux tutoriels disponibles en ligne. Je vais plutÃ´t vous montrer le contenu du fichier `prometheus.yml`.

Pour que Prometheus puisse accÃ©der aux mÃ©triques d'Incus, vous devez ajouter les lignes suivantes dans le fichier `prometheus.yml` :

```yaml
- job_name: 'home-lab'
Â  metrics_path: '/1.0/metrics'
Â  scheme: 'https'
Â  static_configs:
Â  Â  - targets: ['<ip_du_ovn_bridge>:8443']
Â  tls_config:
Â  Â  ca_file: '/etc/prometheus/tls/server.crt'
Â  Â  cert_file: '/etc/prometheus/tls/metrics.crt'
Â  Â  key_file: '/etc/prometheus/tls/metrics.key'
Â  Â  server_name: '<nom_du_serveur_incus>'
```

Une fois que vous avez lancÃ© Prometheus, vous pouvez vÃ©rifier qu'il parvient Ã  rÃ©cupÃ©rer les mÃ©triques en vous rendant Ã  l'adresse suivante : `http://<ip_de_votre_hÃ´te>:9090/targets`

![Image](img/prometheus.png)


### Configuration de Grafana

Comme pour Prometheus, je vous laisse gÃ©rer l'installation de Grafana. Je vais simplement vous montrer comment configurer la source de donnÃ©es.

Pour ajouter la source de donnÃ©es, nous devons spÃ©cifier l'adresse de Prometheus ainsi que le port. C'est ici qu'intervient une fonctionnalitÃ© trÃ¨s pratique d'Incus. Lorsque deux instances se trouvent dans le mÃªme sous-rÃ©seau, il n'est pas nÃ©cessaire d'utiliser leurs adresses IP pour qu'elles puissent communiquer entre elles. Nous pouvons simplement utiliser le nom des instances. Cela est dÃ» au fait qu'Incus met en place un `dnsmasq` local.

Ainsi, lors de la crÃ©ation de la source de donnÃ©es dans Grafana, il est possible d'indiquer le nom de l'instance Incus au lieu de son adresse IP, de la maniÃ¨re suivante : `http://prometheus:9090`

![Image](img/grafana.png)

Maintenant que la source de donnÃ©es a Ã©tÃ© mise en place, nous pouvons crÃ©er un nouveau tableau de bord afin d'exploiter les mÃ©triques.

Vous pouvez obtenir un aperÃ§u des mÃ©triques disponibles dans Incus Ã  l'aide de la commande suivante :

```bash
incus query /1.0/metrics
```

### Configuration des ACLs

Comme je l'ai mentionnÃ© au dÃ©but, les rÃ©seaux OVN permettent de mettre en place des ACLs (listes de contrÃ´le d'accÃ¨s) entre deux instances connectÃ©es au mÃªme rÃ©seau. AprÃ¨s l'ajout d'ACLs, Incus applique automatiquement une rÃ¨gle implicite qui bloque tout le trafic ne correspondant pas explicitement Ã  une rÃ¨gle autorisÃ©e.

C'est ce que nous allons faire ici, en autorisant uniquement :

  - le serveur Grafana Ã  effectuer des requÃªtes TCP sur le port 9090 du serveur Prometheus,
  - et le serveur Prometheus Ã  faire des requÃªtes HTTP vers l'IP du rÃ©seau `ovn-bridge`, afin de rÃ©cupÃ©rer les mÃ©triques d'Incus.

Dans un premier temps, on crÃ©e une ACL nommÃ©e `monitoring` :

```bash
incus network acl create monitoring
```

Ensuite, on ajoute deux rÃ¨gles Ã  cette ACL :

1.  Autoriser le trafic TCP en provenance de Grafana (192.168.10.3) vers Prometheus (192.168.10.2) sur le port 9090 :

<!-- end list -->

```bash
incus network acl rule add monitoring ingress \
Â  Â  protocol=tcp \
Â  Â  source=192.168.10.3 \
Â  Â  destination=192.168.10.2 destination_port=9090 \
Â  Â  state=enabled action=allow
```

2.  Autoriser le trafic TCP en provenance de Prometheus (192.168.10.2) vers l'IP du rÃ©seau `ovn-bridge` (ici 10.26.205.1) sur le port 8443 :

<!-- end list -->

```bash
incus network acl rule add monitoring egress \
Â  Â  protocol=tcp \
Â  Â  source=192.168.10.2 \
Â  Â  destination=10.26.205.1 destination_port=8443 \
Â  Â  state=enabled action=allow
```

Enfin, on applique cette ACL au rÃ©seau `monitoring` :

```bash
incus network set monitoring security.acls=monitoring
```

Le conteneur Grafana ne peut plus envoyer de requÃªtes ICMP (ping) vers Prometheus, mais il peut toujours Ã©tablir une connexion HTTP sur le port 9090.

De mÃªme, Prometheus ne peut plus envoyer de pings vers l'IP du bridge OVN, mais il peut toujours rÃ©cupÃ©rer les mÃ©triques via HTTPS sur le port 8443.

-----

## Conclusion

Dans ce petit lab, nous avons vu les bases d'Incus, Ã  savoir :

  - la crÃ©ation de conteneurs,
  - la crÃ©ation de rÃ©seaux OVN,
  - la crÃ©ation d'ACL.

Ce n'est qu'une brÃ¨ve introduction. Incus couvre Ã©galement d'autres concepts comme les projets, les snapshots ou encore les profils (plus ou moins Ã©quivalents aux templates dans Proxmox). Sans oublier quâ€™Incus sâ€™intÃ¨gre plutÃ´t bien avec des outils comme Terraform ou Ansible.

J'espÃ¨re que cela vous a plu ðŸ˜Š

-----

# Sources

  - [Incus Doc](https://linuxcontainers.org/incus/docs/main/)
  - [LXD Doc](https://documentation.ubuntu.com/microcloud/v2-edge/lxd/)